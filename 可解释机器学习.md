# 可解释机器学习
Ref:
1. [A book for interpretable ML](https://christophm.github.io/interpretable-ml-book/)
2. Manolis Kellis 2021 深度学习在生物学中的应用 第五课


## 概述

可解释机器学习想要做的事情是试图理解深度学习模型时如何学习与判断的。

比如你train了一个基于CNN的模型来识别人脸，效果很不错。但是这个模型究竟是怎么去做到这件事的？也就是如何打开这个黑盒。以CNN来说，一个猜想是每一个filter都是在提取图片中的一些信息特征，这样多个卷积层就是再不断的提取的过程，最终得到的结论。

那么做这样的解释，也就可以得到一些新发现。比方说这样的卷积层都是在识别某一个特征，那么这个特征是不是说对于模型来讲，这个特征就是它判断的依据之一呢。

## 可解释机器学习的分类
1. Ante-hoc，选择决策树之类的可以很轻易解释的简单模型（线性回归也是）
2. Post-hoc，选择复杂的模型如深度学习模型。
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-074928.png)

而Post-hoc是现在面临的主要的问题
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-075023.png)

## 解释深度学习模型
解释深度学习模型，通常从两个角度出发：
1. **解释整个模型（Interpreting models）**，也就是从宏观上去理解，以及理解内部的层所发挥的作用
2. **解释模型的判断（Interpreting decisions）**，试图理解模型时如何做出某个判断的。**一般是采用梯度的方法**

目前应用的最多的是解释模型的判断的方式。
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-075343.png)

![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-075409.png)

### Interpreting Models

![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-075452.png)

#### Weight Visualization
可视化权重的方式是使用的比较广泛的一种。以CNN为例：每一个卷积层都是在提取目标图片的特征。可视化其中的权重便可以理解成在识别图片中哪一些区域符合这样的一个特征。
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-075539.png)

**而在生物学上**，也比较常用。在调控基因组学中，用DNA序列作为输入的深度学习模型，一般会使用one-hot的编码方式。然后使用1维卷积去处理数据，这样每一个filter就可以理解成对应一个特定motif的PSSM矩阵多个filter的卷积操作其实就等价于用多个PSSM矩阵在序列上进行扫描并得到一个**最大匹配结果分数**。这样模型的权重就可以抽象为一系列的motif
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-09-072148.png)

#### Surrogate Model
代理模型，就是采用另外的模型（容易解释的模型）来实现相同的效果，然后用这个模型来解释结果。

#### Data Generation
以分类模型为例，想要找到对应于鹅的这个输出，所拥有最大的$p_\theta(w_c|x)$的概率的输入。也就是与输入同大小的图片
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-080134.png)

而实际上为了限制求得的图片所位于的解的范围还有加上正则化项
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-080134.png)
这里的$x$代表的是输入。

一些相关的研究结果：
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-080559.png)


### Interpreting Decisions
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-080614.png)

主要是利用梯度的方法去获得saliency map的结果来解释（Attribution Methods）；以及研究那一个样本对模型的权重学习贡献最大。

#### Example-based
也就是追溯训练集中，哪一个样本对于模型权重学习贡献度最大。比如模型判别输入图片时候为向日葵的时候，模型学习到这样的能力，哪一个样本对它贡献最大。![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-081401.png)

#### Attribution Methods

![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-081421.png)
也就是对于模型的输出，寻找一个函数来定义 贡献度（attribution values）来描述输入对模型输出的一个贡献值。
这样也就是：对于输入的一个向量$\mathbf{x}=(x1,x2,x3,...)$以及输出$f(\mathbf{x})$都有一个贡献度：$R(\mathbf{x})$，也就解释了每一个输入的标量对于输出的贡献度。

通常这个$R(\mathbf{x}) = \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}$也就是梯度。
这样就可以可视化贡献度得到一个热图的结果：![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-081806.png)

基于定义贡献度为梯度的方式，有许多研究。
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-081847.png)
这样的可视化梯度的结果也叫做 **Saliency Map**。是最常用的解释深度学习模型的输入与输出之间的关系的方法。![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-081937.png)

但是实际上获得的Saliency Map往往会有许多噪声。可能是因为：
1. 梯度是不连续的![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082133.png)随着层数越多，以及使用的激活函数的影响导致$f(x)~x$之间并非是连续的。
2. ![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082334.png)可能是因为激活函数的饱和性所导致的问题

一些相关的论文：![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082413.png)

##### Gradient Based
对于刚刚提到的梯度是不连续的情况，SmoothGrad的文章给出了一个解决方案：![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082550.png)
也就是对输入的图片添加多个噪声，然后去求梯度，最后把这些求出来的梯度求个和。比如：对1张图片进行5次加噪声的处理得到5个图片，然后求出贡献度的结果也有5个，然后合并成一个结果后取平均就可以了。

而对于刚刚激活函数可能存在饱和性的原因，可以给输入的图片乘上一个0~1之间的数使得一些原本会在激活函数后得到一样的结果的值有了一定的区分度![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082843.png)
![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082853.png)


##### Backprop Based
1. 反卷积![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082925.png)

2. ![](https://tf-picture-bed-1259792641.cos.ap-beijing.myqcloud.com/blog/2021-12-11-082937.png)
